{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacbcaea-7e4f-4788-bba0-aa550d6d5787",
   "metadata": {},
   "source": [
    "# Project: Planning my next holidays 锔\n",
    "\n",
    "## on va  nettoyer et analyser les donn茅es que nous avons collect茅es sur les villes et les h么tels.  la fin, il faut les enregistrer dans un seau S3 de notre compte AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d6df7-96a0-4e21-998b-6d1525ee94b5",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f02603-c0bb-4748-a409-8cb82c8a73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.21.13-py3-none-any.whl (132 kB)\n",
      "     || 132 kB 10.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3) (0.10.0)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Using cached s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.25.0,>=1.24.13\n",
      "  Downloading botocore-1.24.13-py3-none-any.whl (8.6 MB)\n",
      "     || 8.6 MB 21.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.25.0,>=1.24.13->boto3) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.25.0,>=1.24.13->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.13->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.21.13 botocore-1.24.13 s3transfer-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "# !pip install plotly==4.8.1\n",
    "# !jupyter labextension install jupyterlab-plotly@4.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4594360-9343-4a2f-8496-6a76a9d73ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import plotly.express as px\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcea1c-4707-4f21-b46e-28a71c9c0caa",
   "metadata": {},
   "source": [
    "## 1. Lire le fichier `.csv` qui contient des informations sur les villes et la m茅t茅o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ecd72b-318e-4670-a228-74d9b3d7334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>main_weather</th>\n",
       "      <th>expected_rain</th>\n",
       "      <th>day_temperature</th>\n",
       "      <th>rank</th>\n",
       "      <th>inverted_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Avignon</td>\n",
       "      <td>43.949249</td>\n",
       "      <td>4.805901</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.65125</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>Saintes Maries de la mer</td>\n",
       "      <td>43.452277</td>\n",
       "      <td>4.428717</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.27375</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>45.757814</td>\n",
       "      <td>4.832011</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.66500</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>Nimes</td>\n",
       "      <td>43.837425</td>\n",
       "      <td>4.360069</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>0.035</td>\n",
       "      <td>11.66500</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Aigues Mortes</td>\n",
       "      <td>43.565823</td>\n",
       "      <td>4.191284</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>0.038</td>\n",
       "      <td>11.58250</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id                      name   latitude  longitude main_weather  \\\n",
       "0       22                   Avignon  43.949249   4.805901        Clear   \n",
       "1       26  Saintes Maries de la mer  43.452277   4.428717        Clear   \n",
       "2       16                      Lyon  45.757814   4.832011        Clear   \n",
       "3       24                     Nimes  43.837425   4.360069       Clouds   \n",
       "4       25             Aigues Mortes  43.565823   4.191284       Clouds   \n",
       "\n",
       "   expected_rain  day_temperature  rank  inverted_rank  \n",
       "0          0.000         11.65125     1             33  \n",
       "1          0.000         11.27375     1             33  \n",
       "2          0.000          8.66500     1             33  \n",
       "3          0.035         11.66500     4             32  \n",
       "4          0.038         11.58250     5             31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = pd.read_csv('res/1_destinations.csv')\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47bdf2-3396-4f1d-91f6-c0495f43e5ce",
   "metadata": {},
   "source": [
    "## 2. Lire les fichiers `.json` contenant les informations sur les h么tels et les enregistrez dans un seul Dataframe pandas. \"Vous pouvez enregistrer autant d'informations que vous le souhaitez, mais n'oubliez pas d'enregistrer au moins ces informations importantes\" :\n",
    "\n",
    "### - le nom de la ville\n",
    "### - id de la ville (vous le trouverez dans le fichier `.csv` sur les villes)\n",
    "### - cr茅er une colonne contenant un identifiant unique de l'h么tel (hotel_id)\n",
    "### - le nom de l'h么tel\n",
    "\n",
    "##  _Si vous stockez des informations textuelles, assurez-vous de les nettoyer de fa莽on  ce qu'elles soient lisibles._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec601d6-7e99-4990-95e9-56ed3d0487e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Strasbourg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(city_name))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Lire les fichiers json et ajouter hotel_id, city_id et city_name dans les DataFrames\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m temp_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m temp_dataset \u001b[38;5;241m=\u001b[39m temp_dataset\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m}, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m temp_dataset\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m city_id\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:612\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:746\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    744\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:768\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    766\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 768\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:880\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 880\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:1133\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1133\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m     )\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1136\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1139\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# R茅cup茅rer tous les fichiers du dossier `res` en commen莽ant par `2_hotels_` et \n",
    "# en finissant par `.json`\n",
    "\n",
    "hotel_files = glob.glob('res/2_hotels_*.json')\n",
    "\n",
    "# Cr茅er un nouveau DataFrame\n",
    "\n",
    "hotels = pd.DataFrame(columns = ['city_id', 'city_name', 'hotel_id', 'name', 'url', 'latitude', 'longitude', 'score', 'description'])\n",
    "\n",
    "# Iterate sur tous les fichiers JSON\n",
    "\n",
    "for f in hotel_files:\n",
    "    city_name = f.split('_')[2].split('.')[0].replace(\"-\",\" \")\n",
    "    city_id = cities.loc[cities['name'] == city_name,'city_id'].values[0]\n",
    "    \n",
    "    print(\"Processing {}\".format(city_name))\n",
    "    \n",
    "    # Lire les fichiers json et ajouter hotel_id, city_id et city_name dans les DataFrames\n",
    "    \n",
    "    temp_dataset = pd.read_json(f)\n",
    "    temp_dataset = temp_dataset.reset_index().rename({'index': 'hotel_id'}, axis = 1)\n",
    "    temp_dataset.loc[:,'city_id'] = city_id\n",
    "    temp_dataset.loc[:,'city_name'] = city_name\n",
    "    \n",
    "   # Nettoyer les champs de texte\n",
    "\n",
    "    temp_dataset.loc[:, 'name'] = temp_dataset['name'].str.replace('\\n', '')\n",
    "    temp_dataset.loc[:, 'url'] = temp_dataset['url'].str.replace('\\n', '')\n",
    "    temp_dataset.loc[:, 'description'] = temp_dataset['description'].str.replace('\\n', '')\n",
    "    \n",
    "   # Extraire la latitude et la longitude\n",
    "    \n",
    "    temp_dataset.loc[:,'coords'] = temp_dataset['coords'].str.split(',')\n",
    "    temp_dataset.loc[:, 'longitude'] = temp_dataset['coords'].apply(lambda x : x[0])\n",
    "    temp_dataset.loc[:, 'latitude'] = temp_dataset['coords'].apply(lambda x : x[1])\n",
    "    \n",
    "    # Suppression de la colonne coords (qui n'est plus utile)\n",
    "    \n",
    "    temp_dataset = temp_dataset.drop('coords', axis=1)\n",
    "    \n",
    "    # Ajouter au cadre de donn茅es de l'h么tel\n",
    "    \n",
    "    hotels = hotels.append(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497a7f1-1958-4787-8a0c-feada3ee91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contr么le\n",
    "hotels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5452f21-b400-4d32-ad9c-844f18a7f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to convenient types\n",
    "hotels.loc[:, 'score'] = hotels['score'].str.replace(',','.')\n",
    "hotels = hotels.astype({'city_id': int,\n",
    "                        'hotel_id': int,\n",
    "                        'latitude': float,\n",
    "                        'longitude': float,\n",
    "                        'score': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62da2a-7572-4eb6-b455-2f52defc8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contr么le\n",
    "hotels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4124c51-820e-4517-a3d6-6f3d821d78f6",
   "metadata": {},
   "source": [
    "### 3. Enregistrez le DataFrame contenant toutes les informations sur les h么tels dans un fichier `.csv` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145cdae-daac-4ba0-bf40-1b0eac2e905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hotels DataFrame into .csv file\n",
    "hotels.to_csv('res/3_hotels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eefd81-f265-46e7-b2f2-f740798e2566",
   "metadata": {},
   "source": [
    "### 4. Facultatif : utilisez Plotly pour afficher tous les h么tels sur une carte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3f769-dbb1-4064-90ab-ced47c2588e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_with_score = hotels.loc[hotels['score'].notnull(),:]\n",
    "\n",
    "fig = px.scatter_mapbox(hotels_with_score, lat=\"latitude\", lon=\"longitude\", hover_name = 'name', zoom = 4,\n",
    "                        hover_data = ['description'],\n",
    "                        color = 'score', color_continuous_scale = 'thermal',\n",
    "                        mapbox_style=\"carto-positron\")\n",
    "fig.show('iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f928d4-815c-4204-9df2-650c7b5882e4",
   "metadata": {},
   "source": [
    "### 5. Utilisez `boto3` pour enregistrer les DataFrames sur les villes et les h么tels dans des fichiers `.csv` situ茅s dans un nouveau seau S3 de votre compte AWS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da31bc-13f0-4799-a7e7-11ca705e83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a new session (if .aws/credentials does not exist)\n",
    "# session = boto3.Session(aws_access_key_id=\"YOUR_ACCESS_KEY_ID\", \n",
    "#                         aws_secret_access_key=\"YOUR_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Declare s3 object and create a new bucket\n",
    "s3 = boto3.resource(\"s3\")  # s3 = session.resource(\"s3\")\n",
    "bucket_name = s3.create_bucket(Bucket=\"m03-jedha-project-040121\")\n",
    "\n",
    "# Export hotels to CSV file and upload it\n",
    "hotels_csv = hotels.to_csv(index=False)\n",
    "put_object = bucket_name.put_object(Key = \"hotels.csv\", Body = hotels_csv)\n",
    "\n",
    "# Do the same for cities\n",
    "cities_csv = cities.to_csv(index=False)\n",
    "put_object = bucket_name.put_object(Key = \"cities.csv\", Body = cities_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814f1c4-1a38-4476-9a09-af18934bf9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
